#
# METAMOD example configuration
#
# This file is authoriative in that all legal directives should be specified here
# Use this file as a starting point for local customization

SERVER = localhost

# ============ General configuration ==============
# Base part of external URL's. Concatenate this with the LOCAL_URL to get the
# full URL:
BASE_PART_OF_EXTERNAL_URL = http://[==SERVER==]:3000

# Set this directive to enable Apache virtualhosts (requires separate DNS hostname)
VIRTUAL_HOST =

# Initial part of local URLs:
LOCAL_URL = /

# posix user for web stuff (in 2.7, only used for catalyst)
# must be same as owner of webrun directory
APPLICATION_USER = www-data

# Application name:
APPLICATION_NAME = Example Application

# Application id (has to be short and unique among applications using the same
# database, use only capital characters A-Z)::
APPLICATION_ID = EXAMPLE

# Directory path for logfiles etc. generated by web applications:
WEBRUN_DIRECTORY = [==CONFIG_DIR==]/../example_webrun

# Mail address for person/group responsible for daily operation of the file
# repository. Used for automatically sent notifications when manual action is
# needed. Also used as login name for the Admin user added to the user
# database while this database is initialized:
OPERATOR_EMAIL = someuser@somedomain.com

# Institution set up for the Admin user during user database initialization:
OPERATOR_INSTITUTION = someinstitution

# Specify here if you want to use external SMTP relay instead of localhost MTA
SMTP_RELAY = smtp.example.com

# ============== Logging configuration ==================
LOG4PERL_CONFIG = [==CONFIG_DIR==]/log4perl_config.ini
LOG4PERL_WATCH_TIME = 30
LOG4PHP_CONFIG = [==CONFIG_DIR==]/log4php_config.ini
LOG4ALL_SYSTEM_LOG = [==WEBRUN_DIRECTORY==]/metamod.log

# ============== Catalyst configuration =================
# lib for Catalyst etc
CATALYST_LIB = /opt/metno-perl-webdev-ver1/lib/perl5

# port used by the Catalyst server
CATALYST_PORT = 3000

# ============== PostgreSQL configuration =================
# Name of the PostgreSQL databases (metadata and userbase):
DATABASE_NAME = metamod_example
USERBASE_NAME = metamod_example_userbase

# PG_ADMIN_USER is the PostgreSQL user who may freely create, modify and
# delete the metadata database.
PG_ADMIN_USER = admin

# PG_WEB_USER is a PostgreSQL user who may read/write data in the metadata
# database. It usually also has a password.
PG_WEB_USER = webuser
PG_WEB_USER_PASSWORD = webuser

# Hostname used for connecting to the PostgreSQL database:
PG_HOST = localhost

# Port used for connecting to the PostgreSQL database:
PG_PORT = 5432

# PG_CONNECTSTRING_* are strings used to indicate hostname and port for
# connecting to the PostgreSQL database. They are found in various
# commands and script functions. These strings should be empty if hostname and
# port are not used:
#
# String used in shell commands psql, createdb and dropdb to connect to the
# database:
PG_CONNECTSTRING_SHELL = --host [==PG_HOST==] --port [==PG_PORT==]

# String used in PHP db_Connect function to connect to the
# database:
PG_CONNECTSTRING_PHP = host=[==PG_HOST==] port=[==PG_PORT==]

# String used in Perl DBI->connect function to connect to the
# database:
PG_CONNECTSTRING_PERL = ;host=[==PG_HOST==];port=[==PG_PORT==];password=admin

# Directory for PostgreSQL contrib libs
# i.e. tsearch2.sql, pgcrypto.sql and lwpostgis.sql
PG_CONTRIB = /usr/share/postgresql/8.4/contrib
# for lucid; change to 8.3 for hardy

# the location of the initialization sql-script for the full-text facilities
PG_TSEARCH2_SCRIPT = [==PG_CONTRIB==]/tsearch2.sql

# the location of the initialization sql-script for postGIS
#PG_POSTGIS_SCRIPT = /usr/share/postgresql-8.3-postgis/lwpostgis.sql
PG_POSTGIS_SCRIPT = /usr/share/postgresql/8.4/contrib/postgis.sql

# the Coordinate System References
# PG_POSTGIS_SYSREF_SCRIPT = /usr/share/postgresql-8.3-postgis/spatial_ref_sys.sql
PG_POSTGIS_SYSREF_SCRIPT = /usr/share/postgresql/8.4/contrib/spatial_ref_sys.sql

# additional coordinate systems, retrieve from e.g. : http://spatialreference.org
PG_POSTGIS_ADDITIONAL_SYSREF =
  INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) values ( 93995, 'epsg', 3995, '+proj=stere +lat_0=90 +lat_ts=-71 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ', 'PROJCS["WGS 84 / Arctic Polar Stereographic",GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],PROJECTION["Polar_Stereographic"],PARAMETER["latitude_of_origin",-71],PARAMETER["central_meridian",0],PARAMETER["scale_factor",1],PARAMETER["false_easting",0],PARAMETER["false_northing",0],AUTHORITY["EPSG","3995"],AXIS["Easting",UNKNOWN],AXIS["Northing",UNKNOWN]]');
  INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) values ( 93031, 'epsg', 3031, '+proj=stere +lat_0=-90 +lat_ts=-71 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ', 'PROJCS["WGS 84 / Antarctic Polar Stereographic",GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],PROJECTION["Polar_Stereographic"],PARAMETER["latitude_of_origin",-71],PARAMETER["central_meridian",0],PARAMETER["scale_factor",1],PARAMETER["false_easting",0],PARAMETER["false_northing",0],AUTHORITY["EPSG","3031"],AXIS["Easting",UNKNOWN],AXIS["Northing",UNKNOWN]]');

# the language to use for the data for full-text indexing, pre-installed are 'default' and 'simple' (pg <= 8.2); 'english' and 'simple' (pg >= 8.3)
# see 'select * from pg_ts_config;'
PG_TSEARCH_LANGUAGE = english

# ============== Other configuration =================
# Main menu beneath the application header.Each line should start with
# an URL followed by a space and some text. The text will be shown in
# the application as a menu item, and the URL will be activated when the
# text is clicked.
# Note that standard sections in METAMOD are always displayed below this menu.
# You only need to configure any external links here.
APP_MENU =
# http://example.com Link description

# Comma-separated list of dataset tags accessible from this application:
DATASET_TAGS = 'MM'

# SRU/ISO23950-searchable datasets
# if a database is shared among different projects
# the tags of all projects will be searchable from each project
SRU2JDBC_TAGS = [==DATASET_TAGS==]

# ============ METAMODBASE configuration ==============
# Path for logfile of php-messages (leave empty to log to webserver-errorlogfile)
# [Are these still in use???]
#PHPLOGFILE = [==WEBRUN_DIRECTORY==]/phplog
# Minimum log level, one of ERROR, WARNING, INFO, DEBUG
#PHPLOGLEVEL = DEBUG

# Name of psql executable:
PSQL = psql

# Name of createdb executable:
CREATEDB = createdb

# Name of dropdb executable:
DROPDB = dropdb

# List of import directories:
IMPORTDIRS = [==WEBRUN_DIRECTORY==]/XML/[==APPLICATION_ID==]

# Seconds to wait between different dataset-import tasks
IMPORT_DATASET_WAIT_SECONDS = 600

# List the supported geographical search environments
SRID_ID_COLUMNS = 93995 93031

# Corresponding short names of SRID_ID in Web-Interface
SRID_ID_NAMES = Artic Antarctic

# define a bounding box (north east south west) where each SRID is valid
SRID_NESW_BOUNDING_BOX_93995 = 90 180 30 -180
SRID_NESW_BOUNDING_BOX_93031 = -30 180 -90 -180

# Translate the map-coordinates to the SRID-coordinates
# srid_coord = (map_coord - offset) * scale_factor
# SRID 93995
# pole is x=280 y=240
# scalefactor is derived from the map, y=540 := lat=60 := ry=-3333134.03
# scale = -3333134.03/(240-540) +- 1 pixel
SRID_MAP_SCALE_FACTOR_X_93995 = 11120
SRID_MAP_OFFSET_X_93995 = 280
SRID_MAP_SCALE_FACTOR_Y_93995 = -11120
SRID_MAP_OFFSET_Y_93995 = 240

# SRID 93031
# pole is x=280 y=280
# scalefactor is derived from the map, y=477 := lat=-70 := ry=-2194494.25
# scale = 2194494.25/(477-280) +- 1 pixel
SRID_MAP_SCALE_FACTOR_X_93031 = 11120
SRID_MAP_OFFSET_X_93031 = 280
SRID_MAP_SCALE_FACTOR_Y_93031 = -11120
SRID_MAP_OFFSET_Y_93031 = 280

# Basic latitude longitude earth (4035 = WGS84)
LONLAT_SRID = 4035

# locate your fimex program for reprojection of data
FIMEX_PROGRAM = fimex

# ============ WMS configuration =======================
# URL to background map server delivering coastlines and reticules
WMS_BACKGROUND_MAPSERVER = http://wms.met.no/maps/

# map names for different projections
WMS_NORTHPOLE_MAP = northpole.map
WMS_SOUTHPOLE_MAP = southpole.map
WMS_WORLD_MAP     = world.map

# ============ METAMODSEARCH configuration ==============

# Max number of columns allowed in the search result page:
SEARCH_APP_MAX_COLUMNS = 5

# Max number of rows displayed for second level datasets with same parent:
SEARCH_APP_MAXROWS_SCNDLEV = 50

# Set of Metadata types to be shown as columns in search results.
# Each line below comprise at least two items (items with several words must be
# enclosed in apostophes). Item1 is MT_name in the Metadatatype database table.
# Item2 is the column heading.
# One optional item is "col=n" where n is a number (1,2,...) designating the
# default column number of the metadata in the result table. The optional item
# "cross=X" sets how a column is shown in a cross table. X="h" makes the
# column values define the horizontal axis of the cross table. X="v" will
# similarly define the vertical axis. X="no" excludes the column to be used in
# cross tables.
SEARCH_APP_SHOW_COLUMNS =
 area 'Areas' col=3 cross=v
 institution 'Institutions' col=2
 variable 'Topics and variables'
 activity_type 'Activity types' col=4 cross=h
 abstract 'Abstract' col=5 cross=no
 datacollection_period 'Datacollection period'
 contact 'Contact (E-mail)'
 title 'Descriptive title for the dataset'
 keywords 'Keywords' cross=no
 Product_name 'Product name'
 references 'References' cross=no
 field_type 'Field type (frequency)'
 forecast_type 'Forecast type'
 Platform_name 'Platform name'
 PI_name 'Principal investigator'
 distribution_statement 'Distribution statement'
 spatial_resolution 'Spatial resolution'
 project_name 'Project name'

# Column used to sort the rows representing second level datasets. Given as
# MT_name in the Metadatatype table.
SEARCH_APP_SORT_COLUMN = datacollection_period

# The sequence by which the search categories are visible in the search
# application. The numbers are keys in the SearchCategory database table.
# In addition to the numbers, the keyword FullText may be used.
SEARCH_CATEGORY_SEQUENCE = topics_and_variables,activity_types,institutions,areas,map_search,datacollection_period,fulltext

# Set default fontsize for the results and the two-way tables (percent):
DEFAULT_FONTSIZE = 80

# ============ METAMODUPLOAD configuration ==============
# Upload application: Set this to 1 for debug output to the screen
# and to the testlog file:
DEBUG = 0

# If EXTERNAL_REPOSITORY = false, METAMOD is the owner of the data repository
# (normal mode). Data will be uploaded through web-frontend or ftp and METAMOD
# will move data to its repository. Otherwise, METAMOD will only get information
# about new data in the external repository and harvest metadata there, without
# moving any data.
EXTERNAL_REPOSITORY = false

# In this case, METAMOD has no responsibilty for moving netCDF
# files into their final destination (i.e. the data repository).
# Files are already in the repository when METAMOD recieves them.
# The responsibility for METAMOD is only to extract metadata,
# check the files and eventually report any irregularities back
# to the data provider.
#EXTERNAL_REPOSITORY = true

# For unknown reasons, sometimes it is neccessary to convert all POST-data
# from UTF8 to latin-1. If this is the case, set the following variable to
# TRUE:
DECODE_FROM_UTF8 = FALSE

# Directory path for files uploaded by the web application:
UPLOAD_DIRECTORY = [==WEBRUN_DIRECTORY==]/webupload

# Directory path for files uploaded by FTP:
UPLOAD_FTP_DIRECTORY = [==WEBRUN_DIRECTORY==]/ftpupload

# Schedule for FTP upload monitor
FTP_CRONTAB     = 30 04 * * *
CLEANUP_CRONTAB = 15 00 * * *

# Required minimum file age (number of minutes) for initiating processing
# of files uploaded through the WEB interface. Files less than this age will
# postpone processing (in the upload_monitor.pl script) of all files with
# the same dataset name. This will give the data provider time to upload
# all files in a batch.
UPLOAD_AGE_THRESHOLD = 10

# Directory path for the top data repository directory. This will
# be a directory accessible through some OPeNDAP server (like THREDDS).
# If no OPeNDAP server is installed, links in the web interface pointing to
# data files may be faulty. This dependence on OPeNDAP will be corrected in
# a future version of the software.
OPENDAP_BASEDIR = data
OPENDAP_DIRECTORY = [==WEBRUN_DIRECTORY==]/[==OPENDAP_BASEDIR==]

# String (PREFIX below) used to build the URL pointing to the THREDDS dataset
# corresponding to a file (METAMOD dataset, level 2). This URL has a structure like
# "http://threddsserver/path_to_thredds_catalog?dataset=PREFIXinstitution/dir/file"
# The PREFIX can be empty. It depends on the THREDDS configuration.
THREDDS_DATASET_PREFIX =

# URL of OPeNDAP server. If no OPeNDAP server is installed, use an URL that
# gives access to the data repository by HTTP download.
OPENDAP_URL = http://thredds.example.com:8081/thredds/catalog/data

# Ownertag for uploaded datasets:
UPLOAD_OWNERTAG = MM

# Max length of directory names created by users:
MAXLENGTH_DIRNAME = 20

# Max length of directory keys created by users:
MAXLENGTH_DIRKEY = 10

# Max size of files to be uploaded (bytes) (can be owerridden by php.ini):
MAX_UPLOAD_SIZE_BYTES = 10000000

# Text in mail body sent to a dataset owner when errors are found in an
# uploaded file. The string [OWNER] is replaced by the name of the dataset
# owner when the mail is sent. [DATASET] is replaced by the actual dataset
# name, and [URL] is replaced by an url to the html-file describing the errors:
EMAIL_BODY_WHEN_UPLOAD_ERROR =
 Dear [OWNER],

 The METAMOD system that automatically check files uploaded to the data
 repository, have found errors in files recently uploaded to the [DATASET]
 dataset. Please find the details on the URL below:

 [URL].

# Subject field in E-mails sent to a dataset owner when errors are found
# in an uploaded file:
EMAIL_SUBJECT_WHEN_UPLOAD_ERROR = METAMOD file upload error

# Mail address used in the "from" field on automatically sent E-mails to
# users:
FROM_ADDRESS = [==OPERATOR_EMAIL==]

# Final greetings and signature included in E-mail to users:
EMAIL_SIGNATURE =
 Best regards,
 The project team for the EXAMPLE project

# Initial content of the [==WEBRUN_DIRECTORY==]/ftp_events file. Note that
# this file can be edited and new events added while the application is in
# operation. An existing file will not be touched by an update of the of the
# METAMOD 2.x software. The initial content will only be used if no ftp_events
# file already exists.
FTP_EVENTS_INITIAL_CONTENT =
 dummy      100 0 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23

# Institutions available in the new user registration form:
INSTITUTION_LIST =
 IXI International Example Institute
 ASI Another Similar Institute

# ============ METAMODQUEST configuration ==============
#
# Produce two different files from the same source file
# (htdocs/qst/quest.php). Each having its own values for the
# following macro variables:
#
#  QUEST_OUTPUT_DIRECTORY     The directory (absolute path) where
#                             XML output files should be written.
#

!substitute_to_file_with_new_name htdocs/qst/quest.php => htdocs/qst/fmmeta.php
QUEST_OUTPUT_DIRECTORY = [==WEBRUN_DIRECTORY==]/XML/[==APPLICATION_ID==]
!end_substitute_to_file_with_new_name

# Ownertag used to tag all dataset entries sent to the database:
QUEST_OWNERTAG = [==UPLOAD_OWNERTAG==]

#
# Configuration of additional metadata editors. You can have as many editors
# a you like. Each line is used for the definition of an additional editor.
#
# The format for each line is a follows.
# <editor id> <path to editor configuration file in json format> <dataset tag>
#
# The URL to each editor is editor/<editor id>
#
#QUEST_CONFIGURATIONS =
# expedition [==CONFIG_DIR==]/qst/expedition.json NOT_IMPORT


# ============ Metamod HARVEST configuration
OAI_HARVEST_VALIDATION_SCHEMA = [==INSTALLATION_DIR==]/common/schema/OAI-PMH.xsd
OAI_HARVEST_SOURCES =
 NP http://risapi.data.npolar.no/oai
 HI http://pegasus.nodc.no:8080/ipy_oai/oai.jsp

# use ordinary crontab syntax to determine times when harvester should run
HARVEST_CRONTAB = 30 04 * * *
# 30 04 * * * = run every night at 04:30
# */10 * * * * = run every ten minutes
# HARVEST_HOUR is no longer in use

# ============ Metamod OAI_PMH configuration
# The content-type the WWW-server delivers back. For debug-puposes,
# "text/plain" is easier to view. On a production site you should use
# "text/xml".
PMH_CONTENT_TYPE = text/xml

# If an unusual port number is used for the base URL, set the following to
# a string like:
#                     .':8080'
# Othervise, leave this empty.
PMH_PORT_NUMBER =

# Repository name:
PMH_REPOSITORY_NAME = Test

# Earliest datastamp:
PMH_EARLIEST_DATESTAMP = 1900-01-01

# Repository Identifier
PMH_REPOSITORY_IDENTIFIER = met.no-TEST

# ** make OAI-PMH identifier the same as ISO-identifier
# i.e. oai:...:metamod/APP/file -> urn:...:APP_file
# This is Perl-eval'ed, so use 1 for yes, 0 for no
PMH_SYNCHRONIZE_ISO_IDENTIFIER = 0

# Maximum mumber of the records to deliver. If there are more records to
# deliver a ResumptionToken will be generated.
PMH_MAXRECORDS = 1000

# List of ownertags availabele for export:
PMH_EXPORT_TAGS = [==DATASET_TAGS==]

# The XML is validated before it is sent to the requester. Metadata
# records that do not validate are marked as deleted. To turn this validation
# off, set PMH_VALIDATION to off.
PMH_VALIDATION = on

# optional set configuration, one set per row ownertag|name|description
# the ownertag needs to be one of the export-tags
PMH_SETCONFIG =


# ============ METAMODTHREDDS configuration ==============
# Name of the THREDDS catalog (the name attribute in the catalog element in
# the THREDDS catalog):
THREDDS_CATALOG_NAME = THREDDS catalog for EXAMPLE data

# Name of the topmost dataset (the name attribute in the topmost dataset
# element in the THREDDS catalog):
THREDDS_TOP_DATASET_NAME = EXAMPLE

# Path to THREDDS catalog directory:
THREDDS_CATALOG_DIR = /path/to/metamod/threddsContent

# File name of THREDDS catalog:
THREDDS_CATALOG_FILE = catalog.xml

# ============ Test configuration ==============
#
# TEST_IMPORT_* are used to set up a test environment for automatic importing
# of datasets into the database and data repository. This involves both the
# METAMODUPLOAD and the METAMODBASE modules.
#
# When testing, a virtual time is used which goes faster than ordinary time.
# The following speedup factor is the number of virtual seconds per real
# second. If set to 0, import testing is turned off.
TEST_IMPORT_SPEEDUP = 100

# The virtual time starts at a specific point in real time. At this point
# the virtual date and time is the same as the real date and time. The
# following number represents this point of time as number of seconds since
# the epoch. (Use the show_time_now.pl utility to get a value for this number).
# *** WARNING *** THIS DATE MUST BE NO OLDER THAN 3 MONTHS OR YOU WILL GET AN INTEGER OVERFLOW!!!
TEST_IMPORT_BASETIME = 1309258594

# Set this value to a '#' to activate sending E-mail regarding errors in
# uploaded files to actual users. It comments out setting the E-mail recipient
# to [==OPERATOR_EMAIL==].
TEST_EMAIL_RECIPIENT =

# ============ Subscription configuration ==============
#
# Configuration of the METAMOD subscription services

# The directory where SMS will look for new transfers to perform.
SUBSCRIPTION_SMS_DIRECTORY = some dir

SUBSCRIPTION_ENABLED = ENABLED

# ============ Authentication configuration ============
#
# Configuration of METAMOD configuration

# The type of authentication to perform. The types DB and LDAP are supported
AUTH_TYPE = DB

# LDAP server used for authentication + base DN
#LDAP_SERVER = ldaps://ldap.example.com
#LDAP_BASE_DN = ou=user,ou=internal,dc=example,dc=com

# ============== Distribution configuration =================

# A comma separated list of distribution statements that are interpreted as
# freely available and can be downloaded via the collection basket.
COLLECTION_BASKET_DIST_STATEMENTS = free, something else

# The maximum number of bytes that are allowed in a collection basket download.
# Used to restrict the load on the server. If this is not set the collection basket
# will use a hard coded default value.
#COLLECTION_BASKET_MAX_SIZE = 524288000
