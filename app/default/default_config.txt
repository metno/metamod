#
# METAMOD default configuration
#
# This file contains sensible default values where relevant, and is read before
# your application's master_config.txt. Values in the latter file will override
# any similar directives below:
#
# This file is authoriative in that all legal directives should be specified here.
# Where no sensible default values exist, the directive is commented out but left
# for documentation purposes.
#
# The most frequently customized variables are also repeated in app/example/master_config.txt.
# Use this file as a starting point for your local configuration.

# ============ Enabled modules ==============

# Set these values to any non-blank string to enable each init.d service
# All services are disabled by default.

# start prepare_download_script?
METAMODBASE_DIRECTORY =

# start ftp_monitor_script?
METAMODUPLOAD_DIRECTORY =

# not used - OAI-PMH always available
METAMODPMH_DIRECTORY =

# start harvester?
METAMODHARVEST_DIRECTORY =

# start create_thredds_catalogs_script?
METAMODTHREDDS_DIRECTORY =

# ============ General configuration ==============

SERVER = localhost

# Base part of external URL's. Do NOT include the Catalyst port number here!
# Concatenate this with the LOCAL_URL to get the full URL:
BASE_PART_OF_EXTERNAL_URL = http://[==SERVER==]

# Set this directive to enable Apache virtualhosts (requires separate DNS hostname)
VIRTUAL_HOST =

# Optional extra Apache config file to be included in virtualhost site
EXTRA_APACHE_CONF =

# Initial part of local URLs:
LOCAL_URL = /metamod

# POSIX user for running Metamod services (including Catalyst)
# Normally same as Apache user, except for development where you may use your login user
# Must be same as owner of webrun directory
APPLICATION_USER = www-data

# Application name:
#APPLICATION_NAME = Example Application

# Application id (has to be short and unique among applications using the same
# database, use only capital characters A-Z)::
#APPLICATION_ID = EXAMPLE

# obsolete - remove from code and use custom templates instead - FIXME
SEARCH_APP_TITLE = Metadata Catalogue Search

# Directory path for logfiles etc. generated by web applications:
WEBRUN_DIRECTORY = [==CONFIG_DIR==]/webrun

# Mail address for person/group responsible for daily operation of the file
# repository. Used for automatically sent notifications when manual action is
# needed. Also used as login name for the Admin user added to the user
# database while this database is initialized:
#OPERATOR_EMAIL = someuser@somedomain.com

# Institution set up for the Admin user during user database initialization:
#OPERATOR_INSTITUTION = someinstitution

# Specify here if you want to use external SMTP relay instead of local MTA (sendmail
# or similar).
# Note that local sendmail normally must be configured to relay to external smtp
# server unless directly connected to the Internet (i.e. not behind a firewall).
# On the other hand Metamod SMTP_RELAY often fails due to a bug in Net::SMTP
# which doesn't send a FQDN in the sender address. See the installation manual
# for more info, and don't forget to test which method works for you.
#SMTP_RELAY = smtp.example.com

# Directory path for local CheckMK scripts (unset to disable CheckMK)
CHECKMK_SCRIPT_DIR = /usr/lib/check_mk_agent/local

# ============== Logging configuration ==================

LOG4PERL_CONFIG = [==CONFIG_DIR==]/log4perl_config.ini
LOG4PERL_WATCH_TIME = 30
LOG4ALL_SYSTEM_LOG = [==WEBRUN_DIRECTORY==]/metamod.log

# ============== Catalyst configuration =================

# lib for Catalyst and other dependencies NOT handled by Carton or Debian
#CATALYST_LIB = /opt/metno-metamod-2.13/local/lib/perl5

# port used by the Catalyst server
CATALYST_PORT = 3000

# ============== PostgreSQL configuration =================

# Hostname used for connecting to the PostgreSQL database:
# leave unset if using localhost, so will use sockets instead of tcp/ip
#PG_HOST = mydbserver.example.com

# Name of the PostgreSQL databases (metadata and userbase):
#DATABASE_NAME = metamod_example
#USERBASE_NAME = metamod_example_userbase

# PG_ADMIN_USER is the PostgreSQL user who may freely create, modify and
# delete the metadata database.
#PG_ADMIN_USER = admin

# you'll need an admin password if creating a new database on a remote server
# for local socket connection, change local ident to trust in pg_hba.conf (see install docs)
#PG_ADMIN_USER_PASSWORD = somethingsecret (optional)

# PG_WEB_USER is a PostgreSQL user who may read/write data in the metadata
# database. It usually also has a password.
#PG_WEB_USER = webuser
#PG_WEB_USER_PASSWORD = secret

# Port used for connecting to the PostgreSQL database:
PG_PORT = 5432

# PG_CONNECTSTRING_* are strings used to indicate hostname and port for
# connecting to the PostgreSQL database. They are found in various
# commands and script functions. These strings should be empty if hostname and
# port are not used:
#
# String used in shell commands psql, createdb and dropdb to connect to the
# database:
#PG_CONNECTSTRING_SHELL = --host [==PG_HOST==] --port [==PG_PORT==]
PG_CONNECTSTRING_SHELL =

# String used in Perl DBI->connect function to connect to the
# database:
#PG_CONNECTSTRING_PERL = ;host=[==PG_HOST==];port=[==PG_PORT==]
PG_CONNECTSTRING_PERL =

# Directory for PostgreSQL contrib libs
# i.e. tsearch2.sql, pgcrypto.sql and lwpostgis.sql
# For Hardy:
#PG_CONTRIB = /usr/share/postgresql/8.3/contrib
# For Lucid:
#PG_CONTRIB = /usr/share/postgresql/8.4/contrib
# For Precise:
#PG_CONTRIB = /usr/share/postgresql/9.1/contrib

# the location of the initialization sql-script for the full-text facilities
# For Hardy and Lucid:
#PG_TSEARCH2_SCRIPT = [==PG_CONTRIB==]/tsearch2.sql
# For Precise it no longer exists and must be blank:
#PG_TSEARCH2_SCRIPT =

# the location of the initialization sql-script for postGIS
# For Hardy:
#PG_CRYPTO_SCRIPT = [==PG_CONTRIB==]/pgcrypto.sql
# For Lucid:--1.0
#PG_CRYPTO_SCRIPT = [==PG_CONTRIB==]/pgcrypto.sql
# For Precise: (leave blank since it is installed differently)
#PG_CRYPTO_SCRIPT =

# the location of the initialization sql-script for postGIS
# For Hardy:
#PG_POSTGIS_SCRIPT = /usr/share/postgresql-8.3-postgis/lwpostgis.sql
# For Lucid:
#PG_POSTGIS_SCRIPT = [==PG_CONTRIB==]/postgis.sql
# For Precise:
#PG_POSTGIS_SCRIPT = [==PG_CONTRIB==]/postgis-1.5/postgis.sql

# the Coordinate System References
# For Hardy:
#PG_POSTGIS_SYSREF_SCRIPT = /usr/share/postgresql-8.3-postgis/spatial_ref_sys.sql
# For Lucid:
#PG_POSTGIS_SYSREF_SCRIPT = [==PG_CONTRIB==]/postgis-2.0/spatial_ref_sys.sql
# For Precise:
#PG_POSTGIS_SYSREF_SCRIPT = [==PG_CONTRIB==]/postgis-1.5/spatial_ref_sys.sql

# additional coordinate systems, retrieve from e.g. : http://spatialreference.org
PG_POSTGIS_ADDITIONAL_SYSREF =
  INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) values ( 93995, 'epsg', 3995, '+proj=stere +lat_0=90 +lat_ts=-71 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ', 'PROJCS["WGS 84 / Arctic Polar Stereographic",GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],PROJECTION["Polar_Stereographic"],PARAMETER["latitude_of_origin",-71],PARAMETER["central_meridian",0],PARAMETER["scale_factor",1],PARAMETER["false_easting",0],PARAMETER["false_northing",0],AUTHORITY["EPSG","3995"],AXIS["Easting",UNKNOWN],AXIS["Northing",UNKNOWN]]');
  INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) values ( 93031, 'epsg', 3031, '+proj=stere +lat_0=-90 +lat_ts=-71 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ', 'PROJCS["WGS 84 / Antarctic Polar Stereographic",GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],PROJECTION["Polar_Stereographic"],PARAMETER["latitude_of_origin",-71],PARAMETER["central_meridian",0],PARAMETER["scale_factor",1],PARAMETER["false_easting",0],PARAMETER["false_northing",0],AUTHORITY["EPSG","3031"],AXIS["Easting",UNKNOWN],AXIS["Northing",UNKNOWN]]');

# the language to use for the data for full-text indexing, pre-installed are 'default' and 'simple' (pg <= 8.2); 'english' and 'simple' (pg >= 8.3)
# see 'select * from pg_ts_config;'
PG_TSEARCH_LANGUAGE = english

# ============== Other configuration =================

# Main menu beneath the application header.Each line should start with
# an URL followed by a space and some text. The text will be shown in
# the application as a menu item, and the URL will be activated when the
# text is clicked.
# Note that standard sections in METAMOD are always displayed below this menu.
# You only need to configure any external links here.
#APP_MENU =
# http://example.com Link description

# Comma-separated list of dataset tags accessible from this application:
#DATASET_TAGS = 'MM'

# SRU/ISO23950-searchable datasets
# if a database is shared among different projects
# the tags of all projects will be searchable from each project
SRU2JDBC_TAGS = [==DATASET_TAGS==]

# ============ METAMODBASE configuration ==============

# Name of psql executable:
PSQL = psql

# Name of createdb executable:
CREATEDB = createdb

# Name of dropdb executable:
DROPDB = dropdb

# List of import directories:
IMPORTDIRS = [==WEBRUN_DIRECTORY==]/XML/[==APPLICATION_ID==]

# Seconds to wait between different dataset-import tasks (is this obsolete now?)
IMPORT_DATASET_WAIT_SECONDS = 600

# List the supported geographical search environments
SRID_ID_COLUMNS = 93995 93031 3995 3031 4326

# Corresponding short names of SRID_ID in Web-Interface
SRID_ID_NAMES = Artic Antarctic Northern Southern World

# define a bounding box (north east south west) where each SRID is valid
SRID_NESW_BOUNDING_BOX_93995 = 90 180 30 -180
SRID_NESW_BOUNDING_BOX_93031 = -30 180 -90 -180
SRID_NESW_BOUNDING_BOX_3995 = 90 180 30 -180
SRID_NESW_BOUNDING_BOX_3031 = -30 180 -90 -180
SRID_NESW_BOUNDING_BOX_4326 = 90 180 -90 -180

# Translate the map-coordinates to the SRID-coordinates (DEPRECATED)
# srid_coord = (map_coord - offset) * scale_factor
# SRID 93995
# pole is x=280 y=240
# scalefactor is derived from the map, y=540 := lat=60 := ry=-3333134.03
# scale = -3333134.03/(240-540) +- 1 pixel
SRID_MAP_SCALE_FACTOR_X_93995 = 11120
SRID_MAP_OFFSET_X_93995 = 280
SRID_MAP_SCALE_FACTOR_Y_93995 = -11120
SRID_MAP_OFFSET_Y_93995 = 240

# SRID 93031
# pole is x=280 y=280
# scalefactor is derived from the map, y=477 := lat=-70 := ry=-2194494.25
# scale = 2194494.25/(477-280) +- 1 pixel
SRID_MAP_SCALE_FACTOR_X_93031 = 11120
SRID_MAP_OFFSET_X_93031 = 280
SRID_MAP_SCALE_FACTOR_Y_93031 = -11120
SRID_MAP_OFFSET_Y_93031 = 280

# Basic latitude longitude earth (4035 = WGS84) # change to 4326?
LONLAT_SRID = 4035

# locate your fimex program for reprojection of data
FIMEX_PROGRAM = /usr/bin/fimex
FIMEX_SCHEMAS = /usr/share/fimex
# default tempdir determined by system
#FIMEX_TEMPDIR = /some/other/tmp

# settings vars which can safely be exposed to monitoring scripts
EXPOSE_CONFIG_SETTINGS = VERSION APPLICATION_ID SERVER CATALYST_PORT VIRTUAL_HOST BASE_PART_OF_EXTERNAL_URL LOCAL_URL CONFIG_DIR WEBRUN_DIRECTORY DATABASE_NAME USERBASE_NAME FIMEX_PROGRAM

# ============ WMS configuration =======================

# urls to WMS background maps
WMS_MAPS =
    EPSG:3031   http://public-wms.met.no/backgroundmaps/southpole.map
    EPSG:32633  http://public-wms.met.no/backgroundmaps/world.map
    EPSG:32661  http://public-wms.met.no/backgroundmaps/northpole.map
    EPSG:32761  http://public-wms.met.no/backgroundmaps/southpole.map
    EPSG:3408   http://public-wms.met.no/backgroundmaps/northpole.map
    EPSG:3409   http://public-wms.met.no/backgroundmaps/southpole.map
    EPSG:3410   http://public-wms.met.no/backgroundmaps/world.map
    EPSG:3411   http://public-wms.met.no/backgroundmaps/northpole.map
    EPSG:3412   http://public-wms.met.no/backgroundmaps/southpole.map
    EPSG:3413   http://public-wms.met.no/backgroundmaps/northpole.map
    EPSG:3995   http://public-wms.met.no/backgroundmaps/northpole.map
    EPSG:4326   http://public-wms.met.no/backgroundmaps/world.map

# list of supported projections (with names from spatialreference.org)
WMS_PROJECTIONS =
    EPSG:3031       'WGS 84 / Antarctic Polar Stereographic'
    EPSG:32633      'WGS 84 / UTM zone 33N'
    EPSG:32661      'WGS 84 / UPS North'
    EPSG:32761      'WGS 84 / UPS South'
    EPSG:3411       'NSIDC Sea Ice Polar Stereographic North'
    EPSG:3412       'NSIDC Sea Ice Polar Stereographic South'
    EPSG:3413       'WGS 84 / NSIDC Sea Ice Polar Stereographic North'
    EPSG:3995       'WGS 84 / Arctic Polar Stereographic'
    EPSG:4326       'WGS 84'

# bounding boxes for each projection (currently used only for dynamic map search, experimentally for transform)
# order is left right bottom top
WMS_BOUNDING_BOXES =
    EPSG:3031       -5000000    5000000     -5000000    5000000
    EPSG:32633      -100000     1100000      3000000    9329005
    EPSG:32661      -3000000    7000000     -3000000    7000000
    EPSG:32761      -3000000    7000000     -3000000    7000000
    EPSG:3411       -5000000    0           0           5000000
    EPSG:3412       -5000000    5000000     -5000000    5000000
    EPSG:3413       -5000000    0           0           5000000
    EPSG:3995       -5000000    5000000     -5000000    5000000
    EPSG:4326       -180        180         -90         90

# URL to background map server delivering coastlines and reticules [DEPRECATED]
WMS_BACKGROUND_MAPSERVER = http://wms.met.no/maps/

# map names for different projections [DEPRECATED]
WMS_NORTHPOLE_MAP = northpole.map
WMS_SOUTHPOLE_MAP = southpole.map
WMS_WORLD_MAP     = world.map

# Max number of layers shown automatically in WMS client
# Actual number may be higher or lower if specified explicitly in wmsinfo
MAX_WMS_LAYERS = 30

# query string to append to WMS URL to get Capabilities document (must not contain ?)
WMS_GET_CAPABILITIES = service=WMS&version=1.3.0&request=GetCapabilities

# ============ METAMODSEARCH configuration ==============

# Max number of columns allowed in the search result page (obsolete?):
SEARCH_APP_MAX_COLUMNS = 5

# Max number of rows displayed for second level datasets with same parent:
SEARCH_APP_MAXROWS_SCNDLEV = 50

# Set of Metadata types to be shown as columns in search results.
# Each line below comprise at least two items (items with several words must be
# enclosed in apostophes). Item1 is MT_name in the Metadatatype database table.
# Item2 is the column heading.
# One optional item is "col=n" where n is a number (1,2,...) designating the
# default column number of the metadata in the result table. The optional item
# "cross=X" sets how a column is shown in a cross table. X="h" makes the
# column values define the horizontal axis of the cross table. X="v" will
# similarly define the vertical axis. X="no" excludes the column to be used in
# cross tables.
SEARCH_APP_SHOW_COLUMNS =
 area 'Areas' col=3 cross=v
 institution 'Institutions' col=2
 variable 'Topics and variables'
 activity_type 'Activity types' col=4 cross=h
 abstract 'Abstract' col=5 cross=no
 datacollection_period 'Datacollection period'
 contact 'Contact (E-mail)'
 title 'Descriptive title for the dataset'
 keywords 'Keywords' cross=no
 Product_name 'Product name'
 references 'References' cross=no
 field_type 'Field type (frequency)'
 forecast_type 'Forecast type'
 Platform_name 'Platform name'
 PI_name 'Principal investigator'
 distribution_statement 'Distribution statement'
 spatial_resolution 'Spatial resolution'
 project_name 'Project name'

# Column used to sort the rows representing second level datasets. Given as
# MT_name in the Metadatatype table.
SEARCH_APP_SORT_COLUMN = datacollection_period

# The sequence by which the search categories are visible in the search
# application. The numbers are keys in the SearchCategory database table.
# In addition to the numbers, the keyword FullText may be used.
SEARCH_CATEGORY_SEQUENCE = topics_and_variables,activity_types,institutions,areas,map_search,datacollection_period,fulltext

# Set default fontsize for the results and the two-way tables (percent) (obsolete?):
DEFAULT_FONTSIZE = 80

# merge transform and timeseries functions into same subpage
CONSOLIDATE_TRANSFORM_FUNCTIONS = false

# use map for reprojection bounding box
WMS_MAP_REPROJECTION = false

# ============ METAMODUPLOAD configuration ==============

# Upload application: Set this to 1 for debug output to the screen
# and to the testlog file: (OBSOLETE - FIXME)
#DEBUG = 0

# If EXTERNAL_REPOSITORY = false (the default), METAMOD is the owner of the data
# repository (normal mode). Data will be uploaded through web-frontend or ftp
# and METAMOD will move data to its repository. Otherwise, METAMOD will only get
# information about new data in the external repository and harvest metadata
# there, without moving any data.
EXTERNAL_REPOSITORY = false

# In this case, METAMOD has no responsibilty for moving netCDF
# files into their final destination (i.e. the data repository).
# Files are already in the repository when METAMOD recieves them.
# The responsibility for METAMOD is only to extract metadata,
# check the files and eventually report any irregularities back
# to the data provider.
#EXTERNAL_REPOSITORY = true

# Directory path for files uploaded by the web application:
UPLOAD_DIRECTORY = [==WEBRUN_DIRECTORY==]/webupload

# Directory path for files uploaded by FTP:
UPLOAD_FTP_DIRECTORY = [==WEBRUN_DIRECTORY==]/ftpupload

# Schedule for FTP upload monitor
#FTP_CRONTAB     = 30 04 * * *
#CLEANUP_CRONTAB = 15 00 * * *

# Required minimum file age (number of minutes) for initiating processing
# of files uploaded through the WEB interface. Files less than this age will
# postpone processing (in the upload_monitor.pl script) of all files with
# the same dataset name. This will give the data provider time to upload
# all files in a batch.
UPLOAD_AGE_THRESHOLD = 10

# Directory path for the top data repository directory. This will
# be a directory accessible through some OPeNDAP server (like THREDDS).
# If no OPeNDAP server is installed, links in the web interface pointing to
# data files may be faulty. This dependence on OPeNDAP will be corrected in
# a future version of the software.
OPENDAP_BASEDIR = data
OPENDAP_DIRECTORY = [==WEBRUN_DIRECTORY==]/[==OPENDAP_BASEDIR==]

# String (PREFIX below) used to build the URL pointing to the THREDDS dataset
# corresponding to a file (METAMOD dataset, level 2). This URL has a structure like
# "http://threddsserver/path_to_thredds_catalog?dataset=PREFIXinstitution/dir/file"
# The PREFIX can be empty. It depends on the THREDDS configuration.
THREDDS_DATASET_PREFIX =

# URL of OPeNDAP server. If no OPeNDAP server is installed, use an URL that
# gives access to the data repository by HTTP download.
#OPENDAP_URL = http://thredds.example.com:8081/thredds/catalog/data

# URL of external timeseries plotter. If not given, internal client-based
# plotting will be performed.
#TIMESERIES_URL=http://ts.example.com/jtimeseries-webservices/thredds/diagram?parameters=[TIMESERIES]&url=[OPENDAP]
TIMESERIES_URL =

# Ownertag for uploaded datasets:
#UPLOAD_OWNERTAG = MM

# Max length of directory names created by users:
MAXLENGTH_DIRNAME = 20

# Max length of directory keys created by users:
MAXLENGTH_DIRKEY = 10

# Max size of files to be uploaded (bytes) (currently not implemented):
#MAX_UPLOAD_SIZE_BYTES = 10000000

# Text in mail body sent to a dataset owner when errors are found in an
# uploaded file. The string [OWNER] is replaced by the name of the dataset
# owner when the mail is sent. [DATASET] is replaced by the actual dataset
# name, and [URL] is replaced by an url to the html-file describing the errors:
EMAIL_BODY_WHEN_UPLOAD_ERROR =
 Dear [OWNER],

 The METAMOD system that automatically check files uploaded to the data
 repository, have found errors in files recently uploaded to the [DATASET]
 dataset. Please find the details on the URL below:

 [URL].

# Subject field in E-mails sent to a dataset owner when errors are found
# in an uploaded file:
EMAIL_SUBJECT_WHEN_UPLOAD_ERROR = METAMOD file upload error

# Mail address used in the "from" field on automatically sent E-mails to
# users:
FROM_ADDRESS = [==OPERATOR_EMAIL==]

# Final greetings and signature included in E-mail to users:
EMAIL_SIGNATURE =
# Best regards,
# The project team for the EXAMPLE project

# Initial content of the [==WEBRUN_DIRECTORY==]/ftp_events file. Note that
# this file can be edited and new events added while the application is in
# operation. An existing file will not be touched by an update of the of the
# METAMOD 2.x software. The initial content will only be used if no ftp_events
# file already exists.
FTP_EVENTS_INITIAL_CONTENT =
 dummy      100 0 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23

# Institutions available in the new user registration form:
#INSTITUTION_LIST =
# IXI International Example Institute
# ASI Another Similar Institute

# ============ METAMODQUEST configuration ==============

# The directory (absolute path) where XML output files should be written.
QUEST_OUTPUT_DIRECTORY = [==WEBRUN_DIRECTORY==]/XML/[==APPLICATION_ID==]

# Ownertag used to tag all dataset entries sent to the database:
QUEST_OWNERTAG = [==UPLOAD_OWNERTAG==]

# OBSOLETE?
# Configuration of additional metadata editors. You can have as many editors
# a you like. Each line is used for the definition of an additional editor.
#
# The format for each line is a follows.
# <editor id> <path to editor configuration file in json format> <dataset tag>
#
# The URL to each editor is editor/<editor id>
#
#QUEST_CONFIGURATIONS =
# expedition [==CONFIG_DIR==]/qst/expedition.json NOT_IMPORT

# ============ Metamod HARVEST configuration

# Add your sources for OAI harvesting as a list of "key url" lines
#OAI_HARVEST_SOURCES =
# XX http://api.example.com/oai
# YY http://test.example.com:8080/ipy_oai/oai.jsp

OAI_HARVEST_VALIDATION_SCHEMA = [==INSTALLATION_DIR==]/common/schema/OAI-PMH.xsd

# use ordinary crontab syntax to determine times when harvester should run
#HARVEST_CRONTAB = 30 04 * * *
# 30 04 * * * = run every night at 04:30
# */10 * * * * = run every ten minutes

# HARVEST_HOUR is no longer in use

# ============ Metamod OAI_PMH configuration

# Repository name:
PMH_REPOSITORY_NAME = [==APPLICATION_NAME==]

# Repository Identifier
PMH_REPOSITORY_IDENTIFIER = [==APPLICATION_ID==]

# Earliest datastamp:
PMH_EARLIEST_DATESTAMP = 1900-01-01

# ** make OAI-PMH identifier the same as ISO-identifier
# i.e. oai:...:metamod/APP/file -> urn:...:APP_file
# This is Perl-eval'ed, so use 1 for yes, 0 for no
PMH_SYNCHRONIZE_ISO_IDENTIFIER = 0

# Maximum mumber of the records to deliver. If there are more records to
# deliver a ResumptionToken will be generated.
PMH_MAXRECORDS = 1000

# List of ownertags availabele for export:
PMH_EXPORT_TAGS = [==DATASET_TAGS==]

# The XML is validated before it is sent to the requester. Metadata
# records that do not validate are marked as deleted. To turn this validation
# off, set PMH_VALIDATION to off.
PMH_VALIDATION = on
# please change this to true/false or 1/0 - FIXME

# Change this to custom path if you want to use custom schemas for validation
PMH_VALIDATION_SCHEMAS =
    dif         [==INSTALLATION_DIR==]/common/schema/dif.xsd
    oai_dc      [==INSTALLATION_DIR==]/common/schema/oai_dc.xsd
    iso19115    [==INSTALLATION_DIR==]/common/schema/iso19139/gmd/gmd.xsd
    iso19139    [==INSTALLATION_DIR==]/common/schema/iso19139/gmd/gmd.xsd
# Always use the latest DIF version
# OAI_DC doesn't seem to have been updated since 2002

# Custom local validator commands to run for specific data formats in OAI-PMH
# (needed for ISO 19139 docs which require locally compiled version of libxml2 in precise)
#PMH_LOCAL_VALIDATION =
#    iso19115  '/opt/local/bin/xmllint --noout --schema [SCHEMA] [FILE]'
#    iso19139  '/opt/local/bin/xmllint --noout --schema [SCHEMA] [FILE]'
# otherwise validation is disabled by default for these formats
# (NOTE: this restriction will be removed in a later version)
PMH_LOCAL_VALIDATION =
    iso19115  '-'
    iso19139  '-'

# optional set configuration, one set per row ownertag|name|description
# the ownertag needs to be one of the export-tags
PMH_SETCONFIG =

# ============ METAMODTHREDDS configuration ==============

# Name of the THREDDS catalog (the name attribute in the catalog element in
# the THREDDS catalog):
#THREDDS_CATALOG_NAME = THREDDS catalog for EXAMPLE data

# Name of the topmost dataset (the name attribute in the topmost dataset
# element in the THREDDS catalog):
#THREDDS_TOP_DATASET_NAME = EXAMPLE

# Path to THREDDS catalog directory:
#THREDDS_CATALOG_DIR = /path/to/metamod/threddsContent

# File name of THREDDS catalog:
#THREDDS_CATALOG_FILE = catalog.xml

# ============ Test configuration ==============
#
# TEST_IMPORT_* are used to set up a test environment for automatic importing
# of datasets into the database and data repository. This involves both the
# METAMODUPLOAD and the METAMODBASE modules.
#
# When testing, a virtual time is used which goes faster than ordinary time.
# The following speedup factor is the number of virtual seconds per real
# second. If set to 0, import testing is turned off.
TEST_IMPORT_SPEEDUP = 0

# The virtual time starts at a specific point in real time. At this point
# the virtual date and time is the same as the real date and time. The
# following number represents this point of time as number of seconds since
# the epoch. (Use the show_time_now.pl utility to get a value for this number).
#
# *** WARNING *** THIS DATE MUST BE NO OLDER THAN 3 MONTHS OR YOU WILL GET AN
# INTEGER OVERFLOW!!! THIS WILL NEED TO BE PERIODICALLY UPDATED! ***
TEST_IMPORT_BASETIME = 1309258594

# Set this value to a '#' to activate sending E-mail regarding errors in
# uploaded files to actual users. It comments out setting the E-mail recipient
# to [==OPERATOR_EMAIL==].
TEST_EMAIL_RECIPIENT =

# ============ Subscription configuration ==============
#
# Configuration of the METAMOD subscription services

# The directory where SMS will look for new transfers to perform.
SUBSCRIPTION_SMS_DIRECTORY =

SUBSCRIPTION_ENABLED = ENABLED
# please change this to true/false or 1/0 - FIXME

# ============ Authentication configuration ============
#
# Configuration of METAMOD configuration

# The type of authentication to perform. The types DB (default) and LDAP are
# supported.
AUTH_TYPE = DB

# LDAP server used for authentication + base DN
#LDAP_SERVER = ldaps://ldap.example.com
#LDAP_BASE_DN = ou=user,ou=internal,dc=example,dc=com

# ============== Distribution configuration =================

# A comma separated list of distribution statements that are interpreted as
# freely available and can be downloaded via the collection basket.
COLLECTION_BASKET_DIST_STATEMENTS = free

# Max number of files in basket
COLLECTION_BASKET_MAX_FILES = 100

# The maximum number of bytes that are allowed in a collection basket download.
# Used to restrict the load on the server. If this is not set the collection basket
# will use a hard coded default value.
COLLECTION_BASKET_MAX_SIZE = 524288000

COLLECTION_BASKET_DOWNLOAD_SCRIPTS =
    download_files.sh      'Unix/Linux shell script'
#    download_files.bat     'Windows Powershell script (Vista and later)'

# ============== Admin configuration =================

# Text in mail body sent to newly registered users.
NEW_USER_GREETING =
 Dear [NAME],

 You have been granted access to [==APPLICATION_NAME==]. ***********
 Username: [USERNAME]
 Password: [RANDOM_PASS]

 [==EMAIL_SIGNATURE==]

# =============== Metadataeditor configuration ================

#METAEDIT_WS_URL = http://metaedit.met.no/metadataeditor/service/metaedit_api/[PROJECT]/[DATASET]
#METAEDIT_SVN_DAV = http://svn.met.no/svn/metamodtest/XML/
#METAEDIT_SVN_DAV_USER = metamod
#METAEDIT_SVN_DAV_PASSWORD = secret
